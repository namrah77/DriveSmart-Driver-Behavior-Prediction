{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Preprocessing , Annotation and Feature extraction**"
      ],
      "metadata": {
        "id": "I6qVLeRfk2my"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjrzcN8BDoEI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "video_path=\"/content/drive/MyDrive/Experimenter_9110002_53.mp4\"\n",
        "# Load the pre-trained face detector and facial landmarks predictor from dlib\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/drive/MyDrive/shape_predictor_68_face_landmarks (1).dat\")\n",
        "\n",
        "# Define EAR and MAR thresholds\n",
        "EAR_THRESHOLD = 0.2\n",
        "MAR_THRESHOLD = 0.4\n",
        "\n",
        "# Function to calculate eye aspect ratio (EAR)\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "\n",
        "# Function to calculate mouth aspect ratio (MAR)\n",
        "def mouth_aspect_ratio(mouth):\n",
        "    A = np.linalg.norm(mouth[14] - mouth[18])\n",
        "    B = np.linalg.norm(mouth[12] - mouth[16])\n",
        "    mar = A / B\n",
        "    return mar\n",
        "\n",
        "# Function to detect faces, annotate frames, and save annotated frames with labels\n",
        "def annotate_frames_with_labels(video_path, frames_dir, annotations_file):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    annotations = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = detector(gray)\n",
        "\n",
        "        for face in faces:\n",
        "            x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
        "            landmarks = predictor(gray, face)\n",
        "            landmarks = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
        "            left_eye = landmarks[36:42]\n",
        "            right_eye = landmarks[42:48]\n",
        "            mouth = landmarks[48:68]\n",
        "            ear_left = eye_aspect_ratio(left_eye)\n",
        "            ear_right = eye_aspect_ratio(right_eye)\n",
        "            mar = mouth_aspect_ratio(mouth)\n",
        "\n",
        "            label = \"Attentive\"\n",
        "            if ear_left < EAR_THRESHOLD or ear_right < EAR_THRESHOLD or mar > MAR_THRESHOLD:\n",
        "                label = \"Drowsy\"\n",
        "\n",
        "            annotations.append({\n",
        "                \"frame_name\": f\"frame_{frame_count}.jpg\",\n",
        "                \"face_bbox\": [x, y, w, h],\n",
        "                \"ear_left\": ear_left,\n",
        "                \"ear_right\": ear_right,\n",
        "                \"mar\": mar,\n",
        "                \"label\": label\n",
        "            })\n",
        "\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Label: {label}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "            frame_path = os.path.join(frames_dir, f\"frame_{frame_count}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    with open(annotations_file, \"w\") as f:\n",
        "        json.dump(annotations, f)\n",
        "\n",
        "# Function to visualize annotated frames\n",
        "def visualize_annotated_frames(frames_dir, annotations_file, num_frames=5):\n",
        "    with open(annotations_file, \"r\") as f:\n",
        "        annotations = json.load(f)\n",
        "\n",
        "    for i, annotation in enumerate(annotations[:num_frames]):\n",
        "        frame_path = os.path.join(frames_dir, annotation[\"frame_name\"])\n",
        "        frame = cv2.imread(frame_path)\n",
        "\n",
        "        x, y, w, h = map(int, annotation[\"face_bbox\"])\n",
        "        label = annotation[\"label\"]\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Label: {label}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        cv2.imshow(f\"Annotated Frame {i+1}\", frame)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Define paths\n",
        "video_path = \"/content/drive/MyDrive/Experimenter_9110002_53.mp4\"  # Change this to the path of your video file\n",
        "save_path = \"/content/drive/MyDrive/preprocessed_video\"\n",
        "\n",
        "# Create save directory if not exists\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# Call annotation function\n",
        "annotate_frames_with_labels(video_path, save_path, os.path.join(save_path, \"annotations.json\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Data Splitting**"
      ],
      "metadata": {
        "id": "A7uYoMONlJ-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "# Define paths\n",
        "parent_folder = \"/content/drive/MyDrive/preprocessed_video\"  # Update with the path to your parent folder containing annotated frames and JSON file\n",
        "train_folder = os.path.join(parent_folder, \"train\")\n",
        "test_folder = os.path.join(parent_folder, \"test\")\n",
        "annotations_file = os.path.join(parent_folder, \"/content/drive/MyDrive/preprocessed_video/annotations.json\")\n",
        "\n",
        "# Load annotations\n",
        "with open(annotations_file, \"r\") as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "# Extract frame names and labels\n",
        "frame_names = [annotation[\"frame_name\"] for annotation in annotations]\n",
        "labels = [annotation[\"label\"] for annotation in annotations]\n",
        "\n",
        "# Split data into training and testing sets (80-20 ratio)\n",
        "train_frames, test_frames, train_annotations, test_annotations = train_test_split(frame_names, annotations, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create train and test folders if they don't exist\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "# Write training annotations to a new JSON file\n",
        "train_annotations_file = os.path.join(train_folder, \"annotations.json\")\n",
        "with open(train_annotations_file, \"w\") as f:\n",
        "    json.dump(train_annotations, f)\n",
        "\n",
        "# Write testing annotations to a new JSON file\n",
        "test_annotations_file = os.path.join(test_folder, \"annotations.json\")\n",
        "with open(test_annotations_file, \"w\") as f:\n",
        "    json.dump(test_annotations, f)\n",
        "\n",
        "# Move training frames to the train folder\n",
        "for frame in train_frames:\n",
        "    src = os.path.join(parent_folder, frame)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, os.path.join(train_folder, frame))\n",
        "    else:\n",
        "        print(f\"File not found: {src}\")\n",
        "\n",
        "# Move testing frames to the test folder\n",
        "for frame in test_frames:\n",
        "    src = os.path.join(parent_folder, frame)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, os.path.join(test_folder, frame))\n",
        "    else:\n",
        "        print(f\"File not found: {src}\")\n",
        "\n",
        "print(\"Data split and files moved successfully.\")\n"
      ],
      "metadata": {
        "id": "dFc7PwMkDqsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Training and Evaluation**"
      ],
      "metadata": {
        "id": "wiXPeF48lRXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "!pip install --upgrade scikit-learn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "dbnsyaCnyq67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define paths\n",
        "train_folder = \"/content/drive/MyDrive/preprocessed_video/train\"\n",
        "test_folder = \"/content/drive/MyDrive/preprocessed_video/test\"\n",
        "\n",
        "# Load annotations\n",
        "train_annotations_file = os.path.join(train_folder, \"annotations.json\")\n",
        "test_annotations_file = os.path.join(test_folder, \"annotations.json\")\n",
        "\n",
        "with open(train_annotations_file, \"r\") as f:\n",
        "    train_annotations = json.load(f)\n",
        "\n",
        "with open(test_annotations_file, \"r\") as f:\n",
        "    test_annotations = json.load(f)\n",
        "\n",
        "# Extract features and labels for drowsiness\n",
        "X_train_drowsy = [[annotation[\"ear_left\"], annotation[\"ear_right\"], annotation[\"mar\"]] for annotation in train_annotations]\n",
        "y_train_drowsy = [1 if annotation[\"label\"] == \"Drowsy\" else 0 for annotation in train_annotations]\n",
        "\n",
        "X_test_drowsy = [[annotation[\"ear_left\"], annotation[\"ear_right\"], annotation[\"mar\"]] for annotation in test_annotations]\n",
        "y_test_drowsy = [1 if annotation[\"label\"] == \"Drowsy\" else 0 for annotation in test_annotations]\n",
        "\n",
        "# Extract features and labels for attentiveness\n",
        "X_train_attentive = [[annotation[\"ear_left\"], annotation[\"ear_right\"], annotation[\"mar\"]] for annotation in train_annotations]\n",
        "y_train_attentive = [1 if annotation[\"label\"] == \"Attentive\" else 0 for annotation in train_annotations]\n",
        "\n",
        "X_test_attentive = [[annotation[\"ear_left\"], annotation[\"ear_right\"], annotation[\"mar\"]] for annotation in test_annotations]\n",
        "y_test_attentive = [1 if annotation[\"label\"] == \"Attentive\" else 0 for annotation in test_annotations]\n",
        "\n",
        "# Train the SVM model for drowsiness\n",
        "model_drowsy = SVC(probability=True)\n",
        "model_drowsy.fit(X_train_drowsy, y_train_drowsy)\n",
        "\n",
        "# Train the SVM model for attentiveness\n",
        "model_attentive = SVC(probability=True)\n",
        "model_attentive.fit(X_train_attentive, y_train_attentive)\n",
        "\n",
        "# Evaluate the model for drowsiness\n",
        "y_pred_drowsy = model_drowsy.predict(X_test_drowsy)\n",
        "report_drowsy = classification_report(y_test_drowsy, y_pred_drowsy)\n",
        "conf_matrix_drowsy = confusion_matrix(y_test_drowsy, y_pred_drowsy)\n",
        "\n",
        "# Evaluate the model for attentiveness\n",
        "y_pred_attentive = model_attentive.predict(X_test_attentive)\n",
        "report_attentive = classification_report(y_test_attentive, y_pred_attentive)\n",
        "conf_matrix_attentive = confusion_matrix(y_test_attentive, y_pred_attentive)\n",
        "# Calculate number of labels\n",
        "num_train_drowsy = sum(y_train_drowsy)\n",
        "num_test_drowsy = sum(y_test_drowsy)\n",
        "num_train_attentive = sum(y_train_attentive)\n",
        "num_test_attentive = sum(y_test_attentive)\n",
        "\n",
        "# Print number of labels\n",
        "print(f\"Number of Drowsy Labels in Training Data: {num_train_drowsy}\")\n",
        "print(f\"Number of Drowsy Labels in Testing Data: {num_test_drowsy}\")\n",
        "print()\n",
        "print(f\"Number of Attentive Labels in Training Data: {num_train_attentive}\")\n",
        "print(f\"Number of Attentive Labels in Testing Data: {num_test_attentive}\")\n",
        "print()\n",
        "\n",
        "# Evaluate the model for drowsiness\n",
        "prob_drowsy = model_drowsy.predict_proba(X_test_drowsy)[:, 1]  # Probability estimates for the positive class (Drowsy)\n",
        "drowsiness_percentage = np.mean(prob_drowsy) * 100\n",
        "\n",
        "# Evaluate the model for attentiveness\n",
        "prob_attentive = model_attentive.predict_proba(X_test_attentive)[:, 1]  # Probability estimates for the positive class (Attentive)\n",
        "attentiveness_percentage = np.mean(prob_attentive) * 100\n",
        "\n",
        "# Define qualification levels\n",
        "drowsiness_qualification = \"Very Drowsy\" if drowsiness_percentage > 60 else \"Drowsy\" if drowsiness_percentage > 30 else \"Slightly Drowsy\"\n",
        "attentiveness_qualification = \"Very Attentive\" if attentiveness_percentage > 60 else \"Attentive\" if attentiveness_percentage > 30 else \"Slightly Attentive\"\n",
        "\n",
        "# Print qualifications along with percentages\n",
        "print(f\"Drowsiness Level: {drowsiness_qualification}, Percentage: {drowsiness_percentage:.2f}%\")\n",
        "print(f\"Attentiveness Level: {attentiveness_qualification}, Percentage: {attentiveness_percentage:.2f}%\")\n",
        "# Print classification report for drowsiness\n",
        "print()\n",
        "print(\"Classification Report for Drowsiness:\")\n",
        "print(report_drowsy)\n",
        "print(\"Confusion Matrix for Drowsiness:\")\n",
        "print(conf_matrix_drowsy)\n",
        "\n",
        "# Print classification report for attentiveness\n",
        "print()\n",
        "print(\"Classification Report for Attentiveness:\")\n",
        "print(report_attentive)\n",
        "print(\"Confusion Matrix for Attentiveness:\")\n",
        "print(conf_matrix_attentive)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkh-RucKxryr",
        "outputId": "a8f982fd-b2bb-4ef6-8cc8-72593a9ff5d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Drowsy Labels in Training Data: 1750\n",
            "Number of Drowsy Labels in Testing Data: 442\n",
            "\n",
            "Number of Attentive Labels in Training Data: 14200\n",
            "Number of Attentive Labels in Testing Data: 3546\n",
            "\n",
            "Drowsiness Level: Slightly Drowsy, Percentage: 11.18%\n",
            "Attentiveness Level: Very Attentive, Percentage: 88.82%\n",
            "\n",
            "Classification Report for Drowsiness:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3546\n",
            "           1       0.97      0.97      0.97       442\n",
            "\n",
            "    accuracy                           0.99      3988\n",
            "   macro avg       0.98      0.98      0.98      3988\n",
            "weighted avg       0.99      0.99      0.99      3988\n",
            "\n",
            "Confusion Matrix for Drowsiness:\n",
            "[[3532   14]\n",
            " [  13  429]]\n",
            "\n",
            "Classification Report for Attentiveness:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       442\n",
            "           1       1.00      1.00      1.00      3546\n",
            "\n",
            "    accuracy                           0.99      3988\n",
            "   macro avg       0.98      0.98      0.98      3988\n",
            "weighted avg       0.99      0.99      0.99      3988\n",
            "\n",
            "Confusion Matrix for Attentiveness:\n",
            "[[ 429   13]\n",
            " [  14 3532]]\n"
          ]
        }
      ]
    }
  ]
}